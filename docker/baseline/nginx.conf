events {
    worker_connections 4096;
}

http {
    upstream vllm_backends {
        # Round-robin load balancing (default)
        server vllm-llama-8b:8000;
        server vllm-qwen-7b:8000;
        server vllm-mistral-7b:8000;
        server vllm-gemma-9b:8000;
        server vllm-llama-70b:8000;
    }

    server {
        listen 80;

        # Increase timeouts for long-running LLM requests
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
        send_timeout 300s;

        # Increase buffer sizes for streaming responses
        proxy_buffering off;
        proxy_buffer_size 128k;
        proxy_buffers 4 256k;
        proxy_busy_buffers_size 256k;

        location / {
            proxy_pass http://vllm_backends;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_cache_bypass $http_upgrade;
        }

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
